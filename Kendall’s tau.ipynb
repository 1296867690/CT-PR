{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b27beed4-b451-4afa-ba08-f1e0a1f3a7a2",
   "metadata": {},
   "source": [
    "### 肯德尔相关系数（与SIR模型对比）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ee4dac-baba-4150-a9ce-a0201a21e047",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b42372-09e8-4e30-808b-28c7ca80d1a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取CSV文件\n",
    "df = pd.read_csv('custom_sorted.csv')\n",
    "\n",
    "# 根据'Centrality'列的值降序排序\n",
    "df_sorted = df.sort_values(by='Centrality', ascending=False)\n",
    "\n",
    "# 获取前十个节点\n",
    "top_20_nodes = df_sorted.head(200)\n",
    "\n",
    "# 打印前十个节点\n",
    "print(\"Top 20 nodes by centrality:\")\n",
    "print(top_20_nodes[['Node', 'Centrality']])\n",
    "\n",
    "# 提取节点ID作为初始感染节点\n",
    "initial_infected_nodes = top_20_nodes['Node'].tolist()\n",
    "\n",
    "# 打印初始感染节点\n",
    "print(\"Initial infected nodes:\")\n",
    "print(initial_infected_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a93ae7d-f414-4c1d-b11b-0094475d003c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SIR模型参数\n",
    "beta = 0.05  # 感染率\n",
    "gamma = 0.01  # 恢复率\n",
    "iterations = 100  # 模拟次数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af19410-cecc-439f-a231-f3b758676f3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# 初始化感染状态：S-易感，I-感染，R-移除\n",
    "def run_SIR(G, beta, gamma, initial_infected, iterations):\n",
    "    # 初始状态：所有节点都易感，只有初始感染节点被感染\n",
    "    final_infection_scale = {node: 0 for node in G.nodes()}  # 记录每个节点的感染规模\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        status = {node: 'S' for node in G.nodes()}  # 每次模拟初始化\n",
    "        for node in initial_infected:import random\n",
    "\n",
    "# 初始化感染状态：S-易感，I-感染，R-移除\n",
    "def run_SIR(G, beta, gamma, initial_infected, iterations):\n",
    "    # 初始状态：所有节点都易感，只有初始感染节点被感染\n",
    "    final_infection_scale = {node: 0 for node in G.nodes()}  # 记录每个节点的感染规模\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        status = {node: 'S' for node in G.nodes()}  # 每次模拟初始化\n",
    "        for node in initial_infected:\n",
    "            status[node] = 'I'\n",
    "\n",
    "        infected_counts = {node: 0 for node in G.nodes()}\n",
    "\n",
    "        while any(state == 'I' for state in status.values()):\n",
    "            new_infected = []\n",
    "            for node in G.nodes():\n",
    "                if status[node] == 'I':  # 节点处于感染状态\n",
    "                    neighbors = list(G.neighbors(node))  # 获取所有邻居节点\n",
    "                    for neighbor in neighbors:\n",
    "                        if status[neighbor] == 'S':  # 邻居是易感的\n",
    "                            # 获取当前边的权重\n",
    "                            edge_weight = G[node][neighbor].get('weight', 1)  # 默认权重为1\n",
    "                            if random.random() < beta * edge_weight:  # 使用权重调整感染概率\n",
    "                                new_infected.append(neighbor)\n",
    "                    if random.random() < gamma:  # 按照恢复率恢复\n",
    "                        status[node] = 'R'\n",
    "\n",
    "            # 更新新的感染者\n",
    "            for node in new_infected:\n",
    "                status[node] = 'I'\n",
    "\n",
    "            # 统计感染规模\n",
    "            for node in G.nodes():\n",
    "                if status[node] == 'I' or status[node] == 'R':\n",
    "                    infected_counts[node] += 1\n",
    "\n",
    "        # 更新每次模拟的感染规模\n",
    "        for node in infected_counts:\n",
    "            final_infection_scale[node] += infected_counts[node]\n",
    "\n",
    "    # 计算平均感染规模\n",
    "    for node in final_infection_scale:\n",
    "        final_infection_scale[node] /= iterations\n",
    "\n",
    "    return final_infection_scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358d0cb5-e01d-46ac-b553-d745a7823761",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 运行 SIR 模型\n",
    "infection_result = run_SIR(G, beta, gamma, initial_infected_nodes, iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e7f7a5-0f89-4c0a-89de-04a2eee63d54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "infection_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bff60d-8655-4ed6-be02-85b1d07e63c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 将结果保存为 CSV 文件\n",
    "output_df = pd.DataFrame(list(infection_result.items()), columns=['Node', 'AverageInfectionScale'])\n",
    "\n",
    "# 对结果进行降序排序\n",
    "sorted_output_df = output_df.sort_values(by='AverageInfectionScale', ascending=False)\n",
    "\n",
    "# 将排序后的结果保存为 CSV 文件\n",
    "sorted_output_df.to_csv('sorted_infection_results200.csv', index=False)\n",
    "\n",
    "print(\"感染结果已保存到 'sorted_infection_results1.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a675a2-03f8-4818-b4b2-172227e9d4bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# 给感染规模文件添加排名\n",
    "# 读取感染规模数据\n",
    "infection_df = pd.read_csv('sorted_infection_results200.csv')\n",
    "\n",
    "# 为相同的 AverageInfectionScale 值分配相同的排名\n",
    "infection_df['Rank'] = infection_df['AverageInfectionScale'].rank(method='min', ascending=False).astype(int)\n",
    "\n",
    "# 保存排名结果\n",
    "infection_df.to_csv('sorted_infection_results_with_ranks200.csv', index=False)\n",
    "\n",
    "print(\"感染规模数据文件已添加排名并保存。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8b5182-4020-4297-9f9a-829980ac3c78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取不同中心性指标的文件，并按照 Centrality 列排序\n",
    "files = {\n",
    "    'Degree': 'degree_sorted.csv',\n",
    "    'Closeness': 'closeness_sorted.csv',\n",
    "    'Betweenness': 'betweenness_sorted.csv',\n",
    "    'Eigenvector': 'eigenvector_sorted.csv',\n",
    "    'Custom': 'custom_sorted1.csv',\n",
    "    'Pagerank':'pagerank_sorted1.csv'\n",
    "}\n",
    "\n",
    "# 按照各个中心性文件中的 Centrality 列进行排序，并添加排名列\n",
    "for centrality_name, file_name in files.items():\n",
    "    # 读取中心性文件\n",
    "    centrality_df = pd.read_csv(file_name)\n",
    "    \n",
    "    # 按照 Centrality 列进行降序排序\n",
    "    sorted_by_centrality = centrality_df.sort_values(by='Centrality', ascending=False)\n",
    "    \n",
    "    # 增加 Rank 列，排名从 1 开始\n",
    "    sorted_by_centrality['Rank'] = sorted_by_centrality['Centrality'].rank(ascending=False, method='min').astype(int)\n",
    "    \n",
    "    # 保存排序后的结果\n",
    "    sorted_by_centrality.to_csv(f'{centrality_name.lower()}_with_ranks1.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b3e577-af99-489c-b7fd-0aa6677b1a35",
   "metadata": {},
   "source": [
    "##### beta = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1d3bbc-a8a3-4f17-9bb7-2840dfc035ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import kendalltau\n",
    "\n",
    "# 中心性文件字典\n",
    "centrality_dict = {\n",
    "    'Degree': 'degree_with_ranks.csv',\n",
    "    'Closeness': 'closeness_with_ranks.csv',\n",
    "    'Betweenness': 'betweenness_with_ranks.csv',\n",
    "    'Eigenvector': 'eigenvector_with_ranks.csv',\n",
    "    'Custom': 'custom_with_ranks1.csv',\n",
    "    'Pagerank':'pagerank_with_ranks1.csv'\n",
    "\n",
    "}\n",
    "\n",
    "# 读取 SIR 模型的感染规模结果（带有排名）\n",
    "infection_results = pd.read_csv('sorted_infection_results_with_ranks200.csv')\n",
    "\n",
    "# 计算 Kendall 的 Tau 相关系数\n",
    "results = {}\n",
    "\n",
    "# 遍历所有中心性文件\n",
    "for method, filename in centrality_dict.items():\n",
    "    # 读取中心性数据（带有排名）\n",
    "    centrality_data = pd.read_csv(filename)\n",
    "    \n",
    "    # 合并中心性数据与感染规模数据\n",
    "    merged_df = pd.merge(centrality_data[['Node', 'Rank']], infection_results[['Node', 'Rank']], on='Node', suffixes=('_Centrality', '_Infection'))\n",
    "    \n",
    "    # 计算 Kendall 的 Tau 相关系数\n",
    "    tau, p_value = kendalltau(merged_df['Rank_Centrality'], merged_df['Rank_Infection'])\n",
    "    results[method] = tau\n",
    "\n",
    "# 保存 Kendall 的 Tau 相关系数结果\n",
    "results_df = pd.DataFrame(list(results.items()), columns=['CentralityMethod', 'KendallTau'])\n",
    "#results_df.to_csv('kendall_tau_results.csv', index=False)\n",
    "results_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8183a54-2e25-45b9-8302-b6aa6b929fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_SIR(G, beta, gamma, initial_infected, iterations):\n",
    "    final_infection_scale = {node: 0 for node in G.nodes()}\n",
    "    for _ in range(iterations):\n",
    "        status = {node: 'S' for node in G.nodes()}\n",
    "        for node in initial_infected:\n",
    "            status[node] = 'I'\n",
    "\n",
    "        infected_counts = {node: 0 for node in G.nodes()}\n",
    "        while any(state == 'I' for state in status.values()):\n",
    "            new_infected = []\n",
    "            for node in G.nodes():\n",
    "                if status[node] == 'I':\n",
    "                    neighbors = list(G.neighbors(node))\n",
    "                    for neighbor in neighbors:\n",
    "                        if status[neighbor] == 'S':\n",
    "                            edge_weight = G[node][neighbor].get('weight', 1)\n",
    "                            if random.random() < beta * edge_weight:\n",
    "                                new_infected.append(neighbor)\n",
    "                    if random.random() < gamma:\n",
    "                        status[node] = 'R'\n",
    "            for node in new_infected:\n",
    "                status[node] = 'I'\n",
    "            for node in G.nodes():\n",
    "                if status[node] == 'I' or status[node] == 'R':\n",
    "                    infected_counts[node] += 1\n",
    "\n",
    "        for node in infected_counts:\n",
    "            final_infection_scale[node] += infected_counts[node]\n",
    "\n",
    "    for node in final_infection_scale:\n",
    "        final_infection_scale[node] /= iterations\n",
    "\n",
    "    return final_infection_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f32e87-95c3-4a2f-b5a2-a0bd90ebe4f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 设定参数\n",
    "beta_values = np.linspace(0, 0.2, 5)  # 从0到0.2的β值\n",
    "gamma = 0.01  # 假设的恢复率\n",
    "\n",
    "iterations = 100  # 模拟次数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ee144c-9c59-402b-9037-a396f9c4c0cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 存储结果并保存为 CSV 文件\n",
    "for beta in beta_values:\n",
    "    infection_result = run_SIR(G, beta, gamma, initial_infected_nodes, iterations)\n",
    "    output_df = pd.DataFrame(list(infection_result.items()), columns=['Node', 'AverageInfectionScale'])\n",
    "    sorted_output_df = output_df.sort_values(by='AverageInfectionScale', ascending=False)\n",
    "    sorted_output_df.to_csv(f'sorted_infection_results_beta_{beta:.2f}1.csv', index=False)\n",
    "\n",
    "print(\"感染结果已保存为不同 β 值的 CSV 文件。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467fd085-ca48-4c4d-b394-281a0302cb09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# β 值列表\n",
    "beta_values = np.linspace(0, 0.2, 5)  # 从0到0.2的β值\n",
    "\n",
    "# 为每个 β 值的感染规模数据添加排名\n",
    "for beta in beta_values:\n",
    "    # 读取感染规模数据\n",
    "    input_file = f'sorted_infection_results_beta_{beta:.2f}1.csv'\n",
    "    output_file = f'sorted_infection_results_with_ranks_beta_{beta:.2f}1.csv'\n",
    "    \n",
    "    infection_df = pd.read_csv(input_file)\n",
    "    \n",
    "    # 为相同的 AverageInfectionScale 值分配相同的排名\n",
    "    infection_df['Rank'] = infection_df['AverageInfectionScale'].rank(method='min', ascending=False).astype(int)\n",
    "    \n",
    "    # 保存排名结果\n",
    "    infection_df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"感染规模数据文件（β={beta:.2f}）已添加排名并保存为 '{output_file}'。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e9b9d4-8024-46e2-8b08-4a755aaca132",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import kendalltau\n",
    "\n",
    "# β 值列表和相应的文件名\n",
    "beta_values = [0.00, 0.05, 0.10, 0.15, 0.20]\n",
    "infection_files = [f'sorted_infection_results_with_ranks_beta_{beta:.2f}1.csv' for beta in beta_values]\n",
    "\n",
    "# 中心性文件字典\n",
    "centrality_dict = {\n",
    "    'DC': 'degree_with_ranks.csv',\n",
    "    'CC': 'closeness_with_ranks.csv',\n",
    "    'BC': 'betweenness_with_ranks.csv',\n",
    "    'EC': 'eigenvector_with_ranks.csv',\n",
    "    'CT-PR': 'custom_with_ranks1.csv'\n",
    "}\n",
    "\n",
    "# 存储 Kendall 的 Tau 结果\n",
    "kendall_tau_results = {}\n",
    "\n",
    "for beta, file_name in zip(beta_values, infection_files):\n",
    "    # 读取 SIR 模型的感染规模结果（带有排名）\n",
    "    infection_results = pd.read_csv(file_name)\n",
    "    \n",
    "    # 计算 Kendall 的 Tau 相关系数\n",
    "    beta_results = {}\n",
    "    \n",
    "    for method, centrality_file in centrality_dict.items():\n",
    "        # 读取中心性数据（带有排名）\n",
    "        centrality_data = pd.read_csv(centrality_file)\n",
    "        \n",
    "        # 合并中心性数据与感染规模数据\n",
    "        merged_df = pd.merge(centrality_data[['Node', 'Rank']], infection_results[['Node', 'Rank']], on='Node', suffixes=('_Centrality', '_Infection'))\n",
    "        \n",
    "        # 计算 Kendall 的 Tau 相关系数\n",
    "        tau, p_value = kendalltau(merged_df['Rank_Centrality'], merged_df['Rank_Infection'])\n",
    "        beta_results[method] = tau\n",
    "    \n",
    "    # 存储结果\n",
    "    kendall_tau_results[beta] = beta_results\n",
    "\n",
    "# 将结果保存为 CSV 文件\n",
    "results_df = pd.DataFrame(kendall_tau_results).T\n",
    "results_df.index.name = 'Beta'\n",
    "results_df.to_csv('kendall_tau_results_by_beta.csv')\n",
    "\n",
    "print(\"Kendall 的 Tau 相关系数结果已保存到 'kendall_tau_results_by_beta.csv'。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1b85f7-bdb2-4596-8340-3abc15b0119b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 读取 Kendall 的 Tau 结果\n",
    "results_df = pd.read_csv('kendall_tau_results_by_beta111.csv', index_col='Beta')\n",
    "\n",
    "# 绘制折线图\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for method in results_df.columns:\n",
    "    plt.plot(results_df.index, results_df[method], marker='o', label=method)\n",
    "\n",
    "plt.xlabel('Beta Value')\n",
    "plt.ylabel('Kendall\\'s Tau')\n",
    "plt.title('Kendall\\'s Tau for Different Beta Values')\n",
    "plt.legend(title='Centrality Method')\n",
    "plt.grid(True)\n",
    "plt.xticks(ticks=results_df.index)\n",
    "plt.tight_layout()\n",
    "plt.savefig('kendall_tau_results_line_plot1.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"Kendall 的 Tau 相关系数折线图已保存为 'kendall_tau_results_line_plot1.png'。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190a5346-60ae-44cd-8b36-4532fb356ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
